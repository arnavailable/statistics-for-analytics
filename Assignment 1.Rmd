---
header-includes:
- \usepackage{amssymb, amsmath, amsthm}
- \usepackage{tabu}
- \newcommand{\E}{\mathbb{E}}
- \newcommand{\var}{{\rm Var}}
- \newcommand{\N}{\mathcal{N}}
output: pdf_document
---

\noindent

```{=tex}
\begin{tabu} to \textwidth {@{}X[4 l] @{}X[r]}
  \textbf{Homework 1}           & \\ 
  \textbf{MSBA 400: Statistical Foundations for Data Analytics}   & \\ 
  \textbf{Arnav Garg}         & \\
  \textbf{UID: 906310841}         & 
\end{tabu}
```
\bigskip

### Question 1

Review the basics of summation notation and covariance formulas. Show that:

a.  $\sum_{i=1}^N (Y_i - \bar{Y}) = 0$

    **Solution:**

    Where:

    $Y_i$ is the individual data point

    $\bar{Y}$ is the mean of all data points

    $\sum_{i=1}^N$ is the summation from element $i=1$ to $i=N$

    $N$ is the total number of data points

    [Solving for LHS:]{.underline}

    $\sum_{i=1}^N (Y_i - \bar{Y})$

    $\Rightarrow \sum_{i=1}^N (Y_i) - \sum_{i=1}^N (\bar{Y})$

    $\Rightarrow \frac{\sum_{i=1}^N (Y_i)}{N}\times N- \bar{Y} \times N \qquad [\sum_{i=1}^N (\bar{Y}) = \bar{Y} \times N]$

    $\Rightarrow \bar{Y} \times N - \bar{Y} \times N \qquad [\bar{Y} = \frac{\sum_{i=1}^N (Y_i)}{N}]$

    $\Rightarrow 0$

    [Solving for RHS:]{.underline}

    $0$

    Since LHS = RHS, hence proved.

b.  $\sum_{i=1}^N (X_i - \bar{X})(Y_i - \bar{Y}) = \sum_{i=1}^N (X_i - \bar{X})Y_i$

    **Solution:**

    [Solving for LHS:]{.underline}

    $\sum_{i=1}^N (X_i - \bar{X})(Y_i - \bar{Y})$

    $\Rightarrow \sum_{i=1}^N (X_i - \bar{X})(Y_i) - \sum_{i=1}^N (X_i - \bar{X})(\bar{Y})$

    $\Rightarrow \sum_{i=1}^N (X_i - \bar{X})(Y_i) - \bar{Y} \times \sum_{i=1}^N (X_i - \bar{X}) \qquad [\bar{Y} \:is\:a\:constant]$

    $\Rightarrow \sum_{i=1}^N (X_i - \bar{X})(Y_i) - 0 \qquad [\sum_{i=1}^N (X_i - \bar{X}) = 0]$

    $\sum_{i=1}^N (X_i - \bar{X})(Y_i)$

    [Solving for RHS:]{.underline}

    $\sum_{i=1}^N (X_i - \bar{X})Y_i$

    Since LHS = RHS, hence proved.

### Question 2

Define both and explain the difference between (a) the expectation of a random variable and (b) the sample average?

**Solution:**

| Basis      | Expectation of a Random Variable                                                                                                                   | Sample Average                                                                       |
|---------------|-----------------------------|-----------------------------|
| Definition | The expected value of a random variable is the average of all its potential outcomes, with each outcome weighted by its likelihood or probability. | Sample average is the mean of all values obtained in a sample.                       |
| Notation   | $E(X), \mu_x$                                                                                                                                      | $\bar{x}$                                                                            |
| Concept    | It is a [theoretical]{.underline} average based on a random variable's probability distribution.                                                   | It is a [practical]{.underline} average based on actual observed data from a sample. |
| Population | It is based on the whole population.                                                                                                               | It is based on a sample, which is a small part of the whole population.              |

### Question 3

a.  Describe the Central Limit Theorem as simply as you can.

    **Solution:**

    Central Limit Theorem states that the sums or averages of not too different random variables converge in to a normal distribution as the number of such sums or averages tend to infinity.

    In simple terms, the more samples we take, the closer our average will get to a normal distribution, even if the original variables themselves aren't normally distributed.

b.  Let $X \sim \textrm{Gamma}(\alpha=2,\ \beta=2)$. For the Gamma distribution, $\alpha$ is often called the "shape" parameter, $\beta$ is often called the "scale" parameter, and the $\mathbb{E}[X]=\alpha\beta$. Plot the density of $X$ and describe what you see. You may find the functions `dgamma()` or `curve()` to be helpful.

    **Solution:**

    I was able to plot the Density Distribution for X \~ Gamma(2,2). I observe that the distribution is positively skewed.

    ```{r}
    curve(dgamma(x, shape = 2, scale = 2), xlab = "Values", ylab = "Density", xlim = c(0, 20), main = "Gamma(2,2) Distribution")
    ```

c.  Let $n$ be the number of draws from that distribution in one sample and $r$ be the number of times we repeat the process of sampling from that distribution. Draw an i.i.d. sample of size $n=10$ from the Gamma(2,2) distribution and calculate the sample average; call this $\bar{X}_n^{(1)}$. Repeat this process $r$ times where $r=1000$ so that you have $\bar{X}_n^{(1)}, \dots, \bar{X}_n^{(r)}$. Plot a histogram of these $r$ values and describe what you see. This is the sampling distribution of $\bar{X}_{(n)}$.

    **Solution:**

    I was able to plot the Sampling Distribution of $\bar{X}_{(10)}$. I observe that the distribution is slightly positively skewed.

    ```{r}
    n = 10
    r = 1000
    xbar = c(1:r)
    for(i in 1:r){
      xbar[i] = mean(rgamma(n, 2, 2))
    }
    hist(xbar, xlab = expression(bar(X)[10]), main = "Sampling Distribution for n = 10", breaks=50)
    ```

d.  Repeat part (c) but with $n=100$. Be sure to produce and describe the histogram. Explain how this illustrates the CLT at work.

    **Solution:**

    I was able to plot the Sampling Distribution for $\bar{X}_{(100)}$. I observe that the distribution is identical to a Normal Distribution which is symmetric and thin-tailed. This practically depicts the Central Limit Theorem in action. As n increases, we observe that the distribution gets closer to a Normal Distribution.

    ```{r}
    n = 100
    r = 1000
    xbar = c(1:r)
    for(i in 1:r){
      xbar[i] = mean(rgamma(n, 2, 2))
    }
    hist(xbar, xlab = expression(bar(X)[100]), main = "Histogram for n = 100", breaks=50)
    ```

### Question 4

The normal distribution is often said to have "thin tails" relative to other distributions like the $t$-distribution. Use random number generation in R to illustrate that a $N(0,1)$ distribution has much thinner tails than a $t$-distribution with 5 degrees of freedom.

A few coding hints: `rnorm()` and `rt()` are the functions in R to draw from a normal distribution and a $t$-distribution. The option `add=TRUE` for the `hist()` command can be used to overlay a second histogram on top of another histogram, and after installing the `scales` package, you can make a blue histogram 50% transparent with the option `col=scales::alpha("blue",0.5)`. Alternatively, you can put two plots side-by-side by first setting the plotting parameter with the code `par(mfrow=c(1,2))`. You can set the range of the x-axis to go from -5 to 5 with the plotting option `xlim=c(-5,5)`.

**Solution:**

I was able to plot the t-distribution on top of N-distribution histogram. We can clearly observe that N-distribution has thinner tails as compared to t-distribution.

```{r}
n = 1000000
hist(rnorm(n), breaks = 50, col = 'blue', xlab = "Values", ylab = "Density", main = "N-distribution vs t-distribution")
hist(rt(n, 5), breaks = 50, col=scales::alpha("blue",0.5), add = TRUE)
```

### Question 5

a.  From the Vanguard data set, compute the standard error of the mean for the `VFIAX` index fund return.

    **Solution:**

    The standard error of mean for the `VFIAX` index fund is 0.00367.

    ```{r}
    library(DataAnalytics)
    data("Vanguard")
    van = Vanguard[ , c(1, 2, 5)]
    vfiax = van[van$ticker == "VFIAX",]
    descStat(vfiax, rnd = 5)[5]
    ```

b.  For this fund, the mean and the standard error of the mean are almost exactly the same. Why is this a problem for a financial analyst who wants to assess the performance of this fund?

    **Solution:**

    The mean for VFIAX = 0.00396 and the standard error of the mean = 0.00367. We can observe that both of them are almost exactly the same. This means that the error with which we calculate the mean is almost equal to the value of the mean itself. It means that the value of mean can vary in the range (0.00396 - 0.00367, 0.00396 + 0.00367) which is almost a 100% deflection from its own value. This is a very large interval, considering the value of the mean itself. It would pose a problem for any financial analyst because the uncertainty of prediction is very high, disallowing the analyst to make accurate predictions.

c.  Calculate the size of the sample which would be required to reduce the standard error of the mean to 1/10th of the size of the mean return.

    **Solution:**

    We know that:

    $SE = \frac{\sigma}{\sqrt{N}}$

    $\Rightarrow \frac{SE_1}{SE_2} = \frac{\frac{\sigma}{\sqrt{N1}}}{\frac{\sigma}{\sqrt{N2}}}$

    $\Rightarrow \frac{SE_1}{SE_2} = \frac{\sqrt{N2}}{\sqrt{N1}}$

    Where:

    $SE_1 = 0.00367$

    $SE_2 = \frac{Mean \:Return}{10} = \frac{0.00396}{10} = 0.000396$

    $N1 = 151$

    $\Rightarrow N2 = 151 \times (\frac{0.00367}{0.000396})^2$

    ```{r}
    151 * ((0.00367 / 0.000396)^2)
    ```

    Hence, the size of the sample which would be required to reduce the standard error of the mean to 1/10th of the size of the mean return is \~12969.

### Question 6 : Sub-setting Observations

We have seen that R has very powerful capabilities to find observations with specific characteristics. The `[<select rows>,<select columns>]` notation is used to subset a data frame. For example, `cars[1:100,]` selects the first 100 observations (rows) of the `cars` data frame.

The most powerful subsetting is done by using what are called logical expressions. A logical expression is an expression that is either TRUE or FALSE. A very simple example would be

```{r}
var = "Ford"     # 1
var == "Ford"    # 2
var != "Ford"    # 3
```

In statement #1, we are assigning the value of "Ford" to the R object called `var`. This makes `var` a character vector with only one element.\
In statement #2, we are comparing what is stored in `var` to the string "Ford", `==` is the "equals" comparison operator. If the contents of `var` is equal to "Ford", then R will produce the result `TRUE`.\
In statement #3, we use the "not equals" comparison operator. #3 will return `FALSE`.

*Logical Comparison Operators*

| Operator |                  Meaning |
|:--------:|-------------------------:|
|   `==`   |                   equals |
|   `!=`   |                not equal |
|   `>`    |             greater than |
|   `<`    |                less than |
|   `>=`   | greater than or equal to |
|   `<=`   |    less than or equal to |

These ideas can be extended to the vectors.

```{r}
vec=c("BMW","Cadillac","Audi")
vec == "BMW"
vec != "BMW"
```

What does this have to do with selecting rows in a data frame (or sub-setting our data)? We can use a vector that only contains "TRUE" or "FALSE" to select rows. Let's look at a simple example.

```{r}
library(DataAnalytics)
data(mvehicles)
cars=mvehicles[mvehicles$bodytype != "Truck",] 
cars_f4 = head(cars,n=4)
cars_f4[,1:3]                                  # show only the first three columns to save space in the output
cars_f4[c(FALSE,TRUE,FALSE,TRUE), 1:3]      
```

The last statement in the code block above has selected the second and fourth rows. This looks like a much more cumbersome way to do it than just `cars_f4[c(2,4),]`. However, the power comes when you try to select on the values of some of the variables in the data frame which describe which observation is which.

As we saw, if we want to select all of the Fords in the data, we can simply write

```{r}
fords = cars[cars$make == "Ford",]
```

We now know how this works. `cars$make == "Ford"` creates a vector with TRUE values marking any observation where `make == "Ford"` and FALSE when not.

### Q6, Part A

1.  Display the contents of the first 50 elements of the vector, `cars$make == "Ford"`, to verify that it is a logical vector.

    **Solution:**

    I was able to implement the code and we can observe that the output is a logical vector.

    ```{r}
    head(cars$make == "Ford", n = 50)
    ```

2.  Subset the `cars` data frame by a two step process to only the "Ford" make. That is, create the row selection logical vector in one statement and select observations from the `cars` data frame in the second.

    **Solution:**

    I was able to subset the `cars` data frame using a two step process by creating a logical vector and using that to select rows from `cars`.

    ```{r}
    vector = cars$make == "Ford"
    output = cars[vector,]
    head(output, n = 10)
    ```

3.  How many Kia observations are there in the `cars` data frame? hint: `nrow()` tells you how many rows are in a data frame.

    **Solution:**

    There are 43 KIA observations in the `cars` data frame.

    ```{r}
    nrow(cars[cars$make == "Kia",])
    ```

4.  How many cars are have a price (emv) that is greater than \$100,000?

    **Solution:**

    There are 37 cars in the `cars` data frame which have a price(emv) greater than \$100,000.

    ```{r}
    nrow(cars[cars$emv > 100000, ])
    ```

We can also couple two logical expressions together using AND `&` or OR `|`. For example, if we want to select all rows with either Kia or Hyundai; we would say `cars[cars$make == "Kia" | cars$make == "Hyundai",]`.

### Q6, part B

What is the average sales for all cars made in Europe with price above \$75,000?

**Solution:**

The average sales for all cars made in Europe with price above \$75,000 is 626.696.

```{r}
europe = cars[, c(5, 7, 17)]
europe = europe[europe$emv > 75000 & europe$origin == "Europe", ]
descStat(europe)
```

In many data sets, there are long text fields which describe an observation. These fields are not formatted in any way and so it is difficult to use simple comparison methods to fetch observations. However, we can use the power of something called regular expressions to find any observations for which a given variable contains some character pattern. Regular expressions are very complicated to use in generality but we can get a lot of use out of a very simple expression.

The `style` variable in `cars` is a general text description variable, We can find the rows for each `style` contains any string by using the command `grepl("string",column,ignore.case=TRUE)`. For example, `grepl("hybrid",cars$style,ignore.case=TRUE)` creates a logical vector (TRUE or FALSE) to help select rows corresponding to hybrids. `cars[grepl("hybrid",cars$style,ignore.case=TRUE),]` will fetch only hybrids.

### Q 6, part C

1.  How many four door vehicles are in cars?

    **Solution:**

    There are 1105 four door vehicles in the `cars` data frame.

    ```{r}
    nrow(cars[grepl("4dr",cars$style,ignore.case=TRUE), ])
    ```

2.  How many four door sedans are in cars?

    **Solution:**

    There are 432 four door sedans in the `cars` data frame.

    ```{r}
    nrow(cars[grepl("4dr",cars$style,ignore.case=TRUE) & cars$bodytype == "Sedan", ])
    ```

### Question 7 : Sales and Price relationships

In this question, use `cars` only.

### Q7, part A

Plot price (horizontal axis) vs. sales (vertical axis) for cars with bodytype == "Sedan". What is the problem with displaying the data in this manner?

**Solution:**

I was able to plot the required graph. However, the problem with displaying data in this manner is that there is a huge spread in data points. The range of data on both X-axis and Y-axis is large. This reduces our ability to perceive the data correctly.

```{r}
sedan = cars[cars$bodytype == "Sedan", ]
plot(sedan$emv, sedan$sales, pch = 20, xlab = "Price", ylab = "Sales", main = "Price vs Sales")
```

### Q7, part B

Plot log(price) vs. log(sales) for the same subset of observations as in part 1. How has this improved the visualization of this data? Are there any disadvantages of taking the log transformation? A very similar but less "violent" transformation is the sqrt transformation. Try the sqrt transformation. Is this useful?

**Solution:**

Log transformation has drastically changed the visualization of the code. Although log transformation reduces the spread of data and enhances our clarity of dependencies, it is a violent transformation. The square root transformation is smoother and less violent in this regard.

```{r}
plot(log(sedan$emv), log(sedan$sales), pch = 20, xlab = "log(Price)", ylab = "log(Sales)", main = "Price vs Sales")
```

```{r}
plot(sqrt(sedan$emv), sqrt(sedan$sales), pch = 20, xlab = "sqrt(Price)", ylab = "sqrt(Sales)", main = "Price vs Sales")
```

### Q7, part C

Economists will tell you that as price increase sales will decreases, all other things being equal. Does this plot support this conclusion?

**Solution:**

The plot totally supports the conclusion. We can observe that as price increases, the sales decrease drastically. Hence, we are able to observe an inverse relationship between price and sales (all other things being equal) which is in accordance to the economist.

### Q7, part D

Fit a regression model to this data. That is, "regress" log(sales) on log(price) (log(sales) is Y or the dependent variable). Plot the fitted line on top of the scatter plot using `abline`.

**Solution:**

I was able to fit a regression model to the data. I also added the fitted line on top of the scatter plot in red color.

```{r}
plot(log(sedan$emv), log(sedan$sales), pch = 20, xlab = "log(Price)", ylab = "log(Sales)", main = "Price vs Sales")
outlm = lm(log(sales)~log(emv), data = sedan)
abline(outlm$coef, lwd = 2, col = "red")
```

### Q7, part E

Predict sales for price = \$45,000 using the model fit in part D. Don't forget to transform back to unit sales by using the `exp()` function.

**Solution:**

The predicted sales for price = \$45,000 using the regression model are 939.5983.

```{r}
exp(predict(outlm, new = data.frame(emv = 45000)))
```
